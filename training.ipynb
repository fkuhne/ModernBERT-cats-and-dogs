{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModernBERT-cats-and-dogs\n",
    "\n",
    "This notebook trains a ModernBERT base model (150M params) in a pre-existing dataset with sentences about:\n",
    "- Cats\n",
    "- Dogs\n",
    "- Undefined (any other topic)\n",
    "\n",
    "BEWARE that training processes regardless the model size usually consume a lot of resources, so only run it if you have a good GPU.\n",
    "\n",
    "Otherwise, I suggest running it in a Colab, which will train the model in just some minutes (for 5 epochs it achieves an F1-score of 94%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from huggingface_hub import HfFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Domestic cats are often referred to as the primary carrier of a parasite that causes toxoplasmosis in humans.',\n",
       "  'Dogs are highly social animals that thrive on interaction with their human family members. They have been known to form strong bonds with their owners and can become depressed if left alone for extended periods of time.',\n",
       "  \"In ancient Egyptian mythology, the cat was associated with the goddess Bastet, often depicted as a woman with the head of a cat. This association is thought to have originated from the cat's ability to protect grain stores from rodents, which were considered pests. As a result, the cat became a symbol of fertility, motherhood, and protection.\",\n",
       "  'Domestic cats are often referred to as the most popular pet in many countries due to their affectionate nature, relatively low maintenance, and ability to provide companionship.',\n",
       "  'Did you know that Greyhounds are bred specifically for their speed, with some dogs reaching up to 45 miles per hour?',\n",
       "  'The domestic cat is a small, typically furry, carnivorous mammal. They are often called housecats when kept as indoor pets or simply cats when there is no need to distinguish them from other felid species. Domestic cats are valued by humans for companionship and for their ability to hunt vermin and other small pests.',\n",
       "  'Felines are highly skilled predators with flexible spines that enable them to twist and turn during the hunt. Their acute hearing and sharp senses allow them to detect prey from great distances.',\n",
       "  'The development of quantum computing has the potential to revolutionize various fields, including medicine, finance, and cryptography. Quantum computers can solve complex problems much faster than classical computers, which could lead to breakthroughs in fields such as genomics and materials science.',\n",
       "  'Dogs have been a human companion for thousands of years, providing assistance, companionship, and affection to many people. Their ability to form strong bonds with humans has made them a popular choice as therapy animals, search and rescue dogs, and guide dogs for the blind.',\n",
       "  'In many cultures, dogs are considered to be part of the family and are often treated with similar affection and loyalty as human children. They are known for their intelligence, loyalty, and ability to form strong bonds with their owners, which can be beneficial for people with disabilities or those who are lonely.'],\n",
       " 'labels': [0, 1, 0, 0, 1, 0, 0, 2, 1, 1]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset from Hugging Face\n",
    "\n",
    "dataset_id = \"fkuhne/cats-and-dogs\"\n",
    "local_dataset_cache = \".datasets/\" + dataset_id\n",
    "\n",
    "train_dataset = load_dataset(\n",
    "    path = dataset_id,\n",
    "    cache_dir = local_dataset_cache,\n",
    "    split='train'\n",
    ")\n",
    "\n",
    "split_dataset = train_dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "if \"label\" in split_dataset[\"train\"].features.keys():\n",
    "    split_dataset = split_dataset.rename_column(\"label\", \"labels\") # to match Trainer\n",
    "\n",
    "split_dataset['train'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    "local_dir = \".models/\" + model_id\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path = model_id,\n",
    "    cache_dir = local_dir,\n",
    "    model_max_length = 8192\n",
    ")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding = True, truncation = True, return_tensors = \"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1365bbbf54e459986a0305722cba727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/449 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be07dce81c454d30a6802ca9a4b746c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['labels', 'input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "\n",
    "tokenized_dataset = split_dataset.map(tokenize, batched = True, remove_columns = [\"text\"])\n",
    "\n",
    "tokenized_dataset[\"train\"].features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model labels - useful for inference\n",
    "\n",
    "labels = tokenized_dataset[\"train\"].features[\"labels\"].names\n",
    "num_labels = len(labels)\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Download the model from huggingface.co/models\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path = model_id,\n",
    "    cache_dir = local_dir,\n",
    "    num_labels = num_labels,\n",
    "    label2id = label2id,\n",
    "    id2label = id2label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training args\n",
    "\n",
    "output_model_dir = \".models/ModernBERT-cats-and-dogs\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = output_model_dir,\n",
    "    per_device_train_batch_size = 32,\n",
    "    per_device_eval_batch_size = 16,\n",
    "    learning_rate = 5e-5,\n",
    "    num_train_epochs = 5,\n",
    "    bf16 = True, # bfloat16 training \n",
    "    optim = \"adamw_torch_fused\", # improved optimizer \n",
    "    # logging & evaluation strategies\n",
    "    logging_strategy = \"steps\",\n",
    "    logging_steps = 100,\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    save_total_limit = 2,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = \"f1\",\n",
    "    # push to hub parameters\n",
    "    push_to_hub = False,\n",
    "    hub_strategy = \"every_save\",\n",
    "    hub_token = HfFolder.get_token(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis = 1)\n",
    "    score = f1_score(\n",
    "            labels, predictions, labels = labels, pos_label = 1, average = \"weighted\"\n",
    "        )\n",
    "    return {\"f1\": float(score) if score == 1 else score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_dataset[\"train\"],\n",
    "    eval_dataset = tokenized_dataset[\"test\"],\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command will take too long in a normal machine. I suggest running this\n",
    "# notebook in a colab session and download the model files from there.\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
